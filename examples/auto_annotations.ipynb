{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "839ee94d-5ead-46da-bd60-5b11e4aaebc4",
   "metadata": {},
   "source": [
    "# Auto Annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ee20f0-007c-4f6a-af1c-ad39b959984b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yanndubois/Desktop/GitHub/alpaca_farm\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "507e6327-cc7e-4135-b462-457a5e71e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpaca_farm.utils import jload\n",
    "from alpaca_farm.auto_annotations.pairwise_annotators import PairwiseAutoAnnotator, SinglePairwiseAutoAnnotator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b8222f-c017-4aae-9b29-cc8210e946fe",
   "metadata": {},
   "source": [
    "The key object that you need for automatic annotations (both for training or for eval) is our `PairwiseAutoAnnotator`. By default the annotator is the pool from Alpaca Farm, for simplicity let's use a single annotator `test` for now.\n",
    "\n",
    "For details about annotators including how to extend them, refer to the [Configuring annotators](#Configuring-annotators) section of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d6dcf4-b0fb-4c56-a1fd-1db509af05e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator = PairwiseAutoAnnotator(annotators_config=\"annotators/test/configs.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b99ac04-0d48-410e-95fd-cf3b1360fc4e",
   "metadata": {},
   "source": [
    "## Annotating paired outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef99a2c-77ef-41e6-9db8-eae091afd952",
   "metadata": {},
   "source": [
    "Now let's annotate some pairwise preference. All we need is some data. The annotator takes in either list of dictionaries, or pandas dataframes. The keys of dictionaries (or columns in dataframe) need to always contain `instruction` and `input` which defines the instruction. The annotator also needs a pair of outputs to compare, if you have a sequence of such pairs under the keys `output_1` and `output_2` then you can directly use `annotate_pairs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ab42c1d-3bda-4797-a1bd-877b958e8657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of paired output:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'If you could help me write an email to my friends inviting them to dinner on Friday, it would be greatly appreciated.',\n",
       "  'input': '',\n",
       "  'output_1': \"Dear Friends, \\r\\n\\r\\nI hope this message finds you well. I'm excited to invite you to dinner on Friday. We'll meet at 7:00 PM at [location]. I look forward to seeing you there. \\r\\n\\r\\nBest,\\r\\n[Name]\",\n",
       "  'output_2': \"Hey everyone! \\n\\nI'm hosting a dinner party this Friday night and I'd love for all of you to come over. We'll have a delicious spread of food and some great conversations. \\n\\nLet me know if you can make it - I'd love to see you all there!\\n\\nCheers,\\n[Your Name]\"}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_pairs = jload(\"examples/data/outputs_pairs.json\")[:6]\n",
    "print(\"Example of paired output:\\n\")\n",
    "outputs_pairs[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67caa934-5a37-429a-affc-dbd182be7c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated = annotator.annotate_pairs(outputs_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dd953df-7eb1-4446-86a9-f3b3fbfba665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'If you could help me write an email to my friends inviting them to dinner on Friday, it would be greatly appreciated.',\n",
       "  'input': '',\n",
       "  'output_1': \"Dear Friends, \\r\\n\\r\\nI hope this message finds you well. I'm excited to invite you to dinner on Friday. We'll meet at 7:00 PM at [location]. I look forward to seeing you there. \\r\\n\\r\\nBest,\\r\\n[Name]\",\n",
       "  'output_2': \"Hey everyone! \\n\\nI'm hosting a dinner party this Friday night and I'd love for all of you to come over. We'll have a delicious spread of food and some great conversations. \\n\\nLet me know if you can make it - I'd love to see you all there!\\n\\nCheers,\\n[Your Name]\",\n",
       "  'annotator': 'davinci003_3',\n",
       "  'preference': 2.0}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e648a4b0-5d19-4bc7-b63e-d4cb4ab4fd51",
   "metadata": {},
   "source": [
    "Here we see that the annotations adds two keys:\n",
    "- `'preference'`: the index of the preferred output, here `preference=2.0` so `output_2` is prefered\n",
    "- `'annotator'`: the name of the simulated annotator as found in the `annotators_config`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ee339-cf40-4a3c-a861-19c265f962bc",
   "metadata": {},
   "source": [
    "`annotate_pairs` is the main function and should be used if you have paired outputs to annotate. In many usecases, however, you  will outputs in different formats. In the following we discuss two additional helper function `annotate_head2head` and `annotate_samples` which are paticularly well suited for the typical format during evaluation and training respectively. Both functions call `annotate_pairs` under the hood after a reformatting step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b41af4-731c-4d12-83b4-9b69f4b2bc3f",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "For evaluation we need two components:\n",
    "- outputs from the model we want to compare\n",
    "- outputs on the same examples from the baseline model\n",
    "\n",
    "Often case both of those components will be in a different list of dictionary (one list for each model). In this case all dictionaries need to contain an `output` column. Let us load such data from our simulated RLHF model and text-davinci-003 baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2a9cce3-0fe9-4dc2-9b49-de59f641e170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of baseline output:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'If you could help me write an email to my friends inviting them to dinner on Friday, it would be greatly appreciated.',\n",
       "  'input': '',\n",
       "  'output': \"Dear Friends, \\r\\n\\r\\nI hope this message finds you well. I'm excited to invite you to dinner on Friday. We'll meet at 7:00 PM at [location]. I look forward to seeing you there. \\r\\n\\r\\nBest,\\r\\n[Name]\"}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_baseline = jload(\"examples/data/outputs_baseline.json\")[:6]\n",
    "print(\"Example of baseline output:\\n\")\n",
    "outputs_baseline[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f808315-da5c-4af3-a026-64e3d07801f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of rlhf output:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'If you could help me write an email to my friends inviting them to dinner on Friday, it would be greatly appreciated.',\n",
       "  'input': '',\n",
       "  'output': \"Dear Friends,\\n\\nI'm planning a dinner party this Friday and I'd love for you to join me! It's going to be a casual night of great food, interesting conversations, and lots of laughs.\\n\\nI'm looking forward to seeing you there. Let me know if you have any dietary restrictions or if you have any questions.\\n\\nSincerely,\\n[Your Name]\"}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_rlhf = jload(\"examples/data/outputs_rlhf.json\")[:6]\n",
    "print(\"Example of rlhf output:\\n\")\n",
    "outputs_rlhf[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6ff9ed-e67b-41df-b706-f2633ec9b909",
   "metadata": {},
   "source": [
    "The annotator's function of interest when we have two sequences of outputs is `annotate_head2head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e613e0ca-2db8-436c-a4c7-bf71de116ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated = annotator.annotate_head2head(outputs_1=outputs_baseline, outputs_2=outputs_rlhf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a72e4e7a-cd40-41c3-87b7-995e323e35d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'If you could help me write an email to my friends inviting them to dinner on Friday, it would be greatly appreciated.',\n",
       "  'input': '',\n",
       "  'output_1': \"Dear Friends, \\r\\n\\r\\nI hope this message finds you well. I'm excited to invite you to dinner on Friday. We'll meet at 7:00 PM at [location]. I look forward to seeing you there. \\r\\n\\r\\nBest,\\r\\n[Name]\",\n",
       "  'output_2': \"Dear Friends,\\n\\nI'm planning a dinner party this Friday and I'd love for you to join me! It's going to be a casual night of great food, interesting conversations, and lots of laughs.\\n\\nI'm looking forward to seeing you there. Let me know if you have any dietary restrictions or if you have any questions.\\n\\nSincerely,\\n[Your Name]\",\n",
       "  'annotator': 'davinci003_3',\n",
       "  'preference': 2.0}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff1699e-eef3-4c98-bc83-512f5f401c6f",
   "metadata": {},
   "source": [
    "We see that the format of the output is the same as before. Here `preference` indicates that the simulator prefered the output `output_2`, which corresponds to our RLHF model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd6a404-4fc1-4f0c-9858-02f24a189b95",
   "metadata": {},
   "source": [
    "## Training\n",
    "For training we typically have multiple outputs for each instruction which are sampled from the same (SFT) model as seen in the following data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50354b51-12c5-4833-81af-549d78ef3dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of different sampled outputs from SFT:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Why is it important to save money?',\n",
       "  'input': '',\n",
       "  'output': 'Saving money is important because it allows you to have financial security in case of emergencies; to be able to afford the things you need; to have money for retirement; and to be able to afford the lifestyle you want. Saving money can also help you build wealth and reach your financial goals. It is important to develop the habit of regularly putting money aside for savings.'},\n",
       " {'instruction': 'Why is it important to save money?',\n",
       "  'input': '',\n",
       "  'output': 'It is important to save money because it can help create a financial cushion in case of an emergency, allow you to pursue goals, and give you more financial security. Having a savings can also give you the opportunity to make more money by investing it. Saving money can also help you prepare for big expenditures, such as buying a car or a house.'},\n",
       " {'instruction': 'Why is it important to save money?',\n",
       "  'input': '',\n",
       "  'output': 'Saving money is important because it provides financial security and allows for the purchase of large-ticket items, such as a car or house, or for emergency situations. It also helps to create financial independence and allows for more flexibility in life, such as taking unpaid time off from work or retiring early. Having money saved also provides peace of mind, knowing that one is prepared for any unexpected events.'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_samples = jload(\"examples/data/multisamples_sft.json\")[:3]\n",
    "print(\"Example of different sampled outputs from SFT:\\n\")\n",
    "outputs_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df755cb-8ff5-478d-b397-682ab3d745e1",
   "metadata": {},
   "source": [
    "In this case, you can use the annotato's `annotate_samples`, which first samples pairs of outputs that have the same instruction/input and then annotate those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc8557da-46fd-4906-a209-a02cc12eef9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prompt_batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.13s/it]\n"
     ]
    }
   ],
   "source": [
    "annotated = annotator.annotate_samples(outputs_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a55348a-a0ca-4fe1-b6d1-b9fa5d1c339b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Why is it important to save money?',\n",
       "  'input': '',\n",
       "  'output_1': 'Saving money is important because it allows you to have financial security in case of emergencies; to be able to afford the things you need; to have money for retirement; and to be able to afford the lifestyle you want. Saving money can also help you build wealth and reach your financial goals. It is important to develop the habit of regularly putting money aside for savings.',\n",
       "  'output_2': 'It is important to save money because it can help create a financial cushion in case of an emergency, allow you to pursue goals, and give you more financial security. Having a savings can also give you the opportunity to make more money by investing it. Saving money can also help you prepare for big expenditures, such as buying a car or a house.',\n",
       "  'annotator': 'davinci003_3',\n",
       "  'preference': 1.0}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da77b705-1845-4994-bd98-17ecfbff3d7f",
   "metadata": {},
   "source": [
    "By default there will only be one pair per instruction,input. If you use `is_unique_instructions=False` then you will get as many pairs as outputs.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515669f8-622c-47f9-9997-c0dedeb797c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Going further"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec356bc8-82cc-4ab0-aa05-b2f3bbce3408",
   "metadata": {},
   "source": [
    "### Adding noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0403b9a8-b444-4861-a837-68fc869dfde9",
   "metadata": {},
   "source": [
    "During training we typically flip the the label with probability 0.25 to emulate the variability of human annotations. To do so you can either:\n",
    "- initialize the annotator with `PairwiseAutoAnnotator(p_label_flip=0.25)`\n",
    "- set the noise of an initialized annotator `annotator.set_noise(p_label_flip=0.25)` \n",
    "- give the noise to annotate_samples `annotate_samples(..., p_label_flip=0.25)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68702d25-3a12-4de6-bef8-e21e79c8d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated = annotator.annotate_samples(outputs_samples, p_label_flip=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d663d65-5da5-40b5-a14b-f2f925649132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Why is it important to save money?',\n",
       "  'input': '',\n",
       "  'output_1': 'Saving money is important because it allows you to have financial security in case of emergencies; to be able to afford the things you need; to have money for retirement; and to be able to afford the lifestyle you want. Saving money can also help you build wealth and reach your financial goals. It is important to develop the habit of regularly putting money aside for savings.',\n",
       "  'output_2': 'It is important to save money because it can help create a financial cushion in case of an emergency, allow you to pursue goals, and give you more financial security. Having a savings can also give you the opportunity to make more money by investing it. Saving money can also help you prepare for big expenditures, such as buying a car or a house.',\n",
       "  'annotator': 'davinci003_3',\n",
       "  'preference': 2.0}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a596a8-0941-4e19-b19a-ee03dad7c1e1",
   "metadata": {},
   "source": [
    "### Cost & time efficiency: avoiding duplicate annotation\n",
    "Often time you will find yourself reannotating examples that you already annotated. This is particularly true if you sample many times from the same model (eg to get pairwise preferences for training or to evaluate best-of-n) or if the instructions you are considering require short outputs => many models might give the same exact answer.\n",
    "\n",
    "This means that you have to spend unecessary money and time. Thankfully `PairwiseAutoAnnotator` stores previous annotations and will reuse those. For example, let us reannotate the previous evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58d43c91-0ef4-417e-bbb2-ce585f6c35ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated = annotator.annotate_head2head(outputs_1=outputs_baseline, outputs_2=outputs_rlhf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd5e9051-23fe-4294-9993-0c7afbc74495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'If you could help me write an email to my friends inviting them to dinner on Friday, it would be greatly appreciated.',\n",
       "  'input': '',\n",
       "  'output_1': \"Dear Friends, \\r\\n\\r\\nI hope this message finds you well. I'm excited to invite you to dinner on Friday. We'll meet at 7:00 PM at [location]. I look forward to seeing you there. \\r\\n\\r\\nBest,\\r\\n[Name]\",\n",
       "  'output_2': \"Dear Friends,\\n\\nI'm planning a dinner party this Friday and I'd love for you to join me! It's going to be a casual night of great food, interesting conversations, and lots of laughs.\\n\\nI'm looking forward to seeing you there. Let me know if you have any dietary restrictions or if you have any questions.\\n\\nSincerely,\\n[Your Name]\",\n",
       "  'annotator': 'davinci003_3',\n",
       "  'preference': 2.0}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84836c18-9f26-4b1f-8660-7f2fa39817ee",
   "metadata": {},
   "source": [
    "We now get the annotations without actually having to reannotate any example.\n",
    "By default, this the previous annotations are only stored in memory. If you want those to be stateful, you need to either give `saving_path` to the constructor of `PairwiseAutoAnnotator` (automatically save and loads) or manually call `save` and `load`.\n",
    "Here's an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed7c4e90-0648-41ef-b903-71dc0a3f627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path = \"examples/data/annotations.json\"\n",
    "annotator.save(saving_path) # manually save the previous annotation\n",
    "new_annotator = PairwiseAutoAnnotator(annotators_config=\"annotators/test/configs.yaml\",\n",
    "                                     saving_path=saving_path # will automatically load and save future annotations\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da900044-8e27-4006-b820-20b3a365c6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'If you could help me write an email to my friends inviting them to dinner on Friday, it would be greatly appreciated.',\n",
       "  'input': '',\n",
       "  'output_1': \"Dear Friends, \\r\\n\\r\\nI hope this message finds you well. I'm excited to invite you to dinner on Friday. We'll meet at 7:00 PM at [location]. I look forward to seeing you there. \\r\\n\\r\\nBest,\\r\\n[Name]\",\n",
       "  'output_2': \"Dear Friends,\\n\\nI'm planning a dinner party this Friday and I'd love for you to join me! It's going to be a casual night of great food, interesting conversations, and lots of laughs.\\n\\nI'm looking forward to seeing you there. Let me know if you have any dietary restrictions or if you have any questions.\\n\\nSincerely,\\n[Your Name]\",\n",
       "  'annotator': 'davinci003_3',\n",
       "  'preference': 2.0}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated = new_annotator.annotate_head2head(outputs_1=outputs_baseline, outputs_2=outputs_rlhf)\n",
    "annotated[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea60a22-a387-4309-8d1b-b78bdcac5a5a",
   "metadata": {},
   "source": [
    "We suggest that you simply set `saving_path=...` when initializing the annotator and you will never have to deal with manual saving and loading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb89a3-7200-4f58-a7f5-9175f36d7cad",
   "metadata": {},
   "source": [
    "### Evaluating win rates "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78922f60-a9aa-4383-b18d-c95a93c6546c",
   "metadata": {},
   "source": [
    "Let's show how to get win rates from annotations using our actual pool of annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826421f1-e644-42c9-9375-d8b08fb958ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpaca_farm.auto_annotations.analysis import head2head_to_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ffaa6c-9570-4384-b157-d6f95b6d90ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the following is selfinstruct eval\n",
    "outputs_baseline = jload(\"examples/data/outputs_baseline.json\")\n",
    "outputs_rlhf = jload(\"examples/data/outputs_rlhf.json\")\n",
    "outputs_sft = jload(\"examples/data/outputs_sft.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e000d42-6c37-40c6-81ac-eef3d34a4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_pool = PairwiseAutoAnnotator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c05eb80-0f24-4570-86ea-40da1a2a95a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Annotating 12 examples with davinci003_4\n",
      "INFO:root:Auto annotating 12 prompts using text-davinci-003.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 200, 'temperature': 1.0}\n",
      "INFO:root:Decoding with OpenAI API model text-davinci-003 and numproc == 1.\n",
      "prompt_batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.13s/it]\n",
      "INFO:root:Annotating 19 examples with davinci003_3\n",
      "INFO:root:Auto annotating 5 prompts using text-davinci-003.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 200, 'temperature': 1.0}\n",
      "INFO:root:Decoding with OpenAI API model text-davinci-003 and numproc == 1.\n",
      "prompt_batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.78s/it]\n",
      "INFO:root:Annotating 18 examples with davinci003_2\n",
      "INFO:root:Auto annotating 18 prompts using text-davinci-003.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 200, 'temperature': 1.0}\n",
      "INFO:root:Decoding with OpenAI API model text-davinci-003 and numproc == 1.\n",
      "prompt_batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.08it/s]\n",
      "INFO:root:Annotating 17 examples with davinci003_1\n",
      "INFO:root:Auto annotating 5 prompts using text-davinci-003.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 200, 'temperature': 1.0}\n",
      "INFO:root:Decoding with OpenAI API model text-davinci-003 and numproc == 1.\n",
      "prompt_batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.10s/it]\n",
      "INFO:root:Annotating 18 examples with chatgpt_4\n",
      "INFO:root:Auto annotating 18 prompts using gpt-3.5-turbo-0301.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 20, 'temperature': 1.0, 'logit_bias': {21279: -100, 63295: -100, 4155: -100, 11995: -100, 25215: -100, 50344: -100, 59047: -100, 2196: -100, 2181: -100, 21704: -100, 19701: -100, 5207: 7, 320: 7, 64: 7, 8: 7, 65: 7}}\n",
      "INFO:root:Decoding with OpenAI API model gpt-3.5-turbo-0301 and numproc == 5.\n",
      "prompt_batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:02<00:00,  6.41it/s]\n",
      "INFO:root:Annotating 19 examples with chatgpt_3\n",
      "INFO:root:Auto annotating 19 prompts using gpt-3.5-turbo-0301.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 20, 'temperature': 1.0, 'logit_bias': {21279: -100, 63295: -100, 4155: -100, 11995: -100, 25215: -100, 50344: -100, 59047: -100, 2196: -100, 2181: -100, 21704: -100, 19701: -100, 5207: 7, 320: 7, 64: 7, 8: 7, 65: 7}}\n",
      "INFO:root:Decoding with OpenAI API model gpt-3.5-turbo-0301 and numproc == 5.\n",
      "prompt_batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:02<00:00,  6.45it/s]\n",
      "INFO:root:Annotating 29 examples with chatgpt_2\n",
      "INFO:root:Auto annotating 29 prompts using gpt-3.5-turbo-0301.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 150, 'temperature': 1.0, 'logit_bias': {21279: -100, 63295: -100, 4155: -100, 11995: -100, 25215: -100, 50344: -100, 59047: -100, 2196: -100, 2181: -100, 21704: -100, 19701: -100}}\n",
      "INFO:root:Decoding with OpenAI API model gpt-3.5-turbo-0301 and numproc == 5.\n",
      "prompt_batches:  34%|██████████████████████████████████████▌                                                                         | 10/29 [00:13<00:22,  1.17s/it]WARNING:root:OpenAIError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 234441c1a8ae2bdb554351e687d523f3 in your message.).\n",
      "WARNING:root:Hit request rate limit; retrying...\n",
      "WARNING:root:Switching to organization: org-aGS1aYCpHCgg5HGJjdcvj1Gi for OAI API key.\n",
      "prompt_batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [01:33<00:00,  3.21s/it]\n",
      "INFO:root:Annotating 20 examples with chatgpt_1\n",
      "INFO:root:Auto annotating 20 prompts using gpt-3.5-turbo-0301.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 50, 'temperature': 1.0, 'logit_bias': {21279: -100, 63295: -100, 4155: -100, 11995: -100, 25215: -100, 50344: -100, 59047: -100, 2196: -100, 2181: -100, 21704: -100, 19701: -100, 5207: 7, 320: 7, 64: 7, 8: 7, 65: 7}}\n",
      "INFO:root:Decoding with OpenAI API model gpt-3.5-turbo-0301 and numproc == 5.\n",
      "prompt_batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.17it/s]\n",
      "INFO:root:Annotating 14 examples with gpt4_5\n",
      "INFO:root:Auto annotating 4 prompts using gpt-4-0314.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 250, 'temperature': 1.0}\n",
      "INFO:root:Decoding with OpenAI API model gpt-4-0314 and numproc == 5.\n",
      "prompt_batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:21<00:00,  5.35s/it]\n",
      "INFO:root:Annotating 24 examples with gpt4_4\n",
      "INFO:root:Auto annotating 24 prompts using gpt-4-0314.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 20, 'temperature': 1.0, 'logit_bias': {21279: -100, 63295: -100, 4155: -100, 11995: -100, 25215: -100, 50344: -100, 59047: -100, 2196: -100, 2181: -100, 21704: -100, 19701: -100, 5207: 7, 320: 7, 64: 7, 8: 7, 65: 7}}\n",
      "INFO:root:Decoding with OpenAI API model gpt-4-0314 and numproc == 5.\n",
      "prompt_batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:09<00:00,  2.42it/s]\n",
      "INFO:root:Annotating 21 examples with gpt4_3\n",
      "INFO:root:Auto annotating 5 prompts using gpt-4-0314.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 250, 'temperature': 1.0}\n",
      "INFO:root:Decoding with OpenAI API model gpt-4-0314 and numproc == 5.\n",
      "prompt_batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.44s/it]\n",
      "INFO:root:Annotating 17 examples with gpt4_2\n",
      "INFO:root:Auto annotating 4 prompts using gpt-4-0314.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 250, 'temperature': 1.0}\n",
      "INFO:root:Decoding with OpenAI API model gpt-4-0314 and numproc == 5.\n",
      "prompt_batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:28<00:00,  7.05s/it]\n",
      "INFO:root:Annotating 23 examples with gpt4_1\n",
      "INFO:root:Auto annotating 6 prompts using gpt-4-0314.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 600, 'temperature': 1.0}\n",
      "INFO:root:Decoding with OpenAI API model gpt-4-0314 and numproc == 5.\n",
      "prompt_batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [01:15<00:00, 12.54s/it]\n"
     ]
    }
   ],
   "source": [
    "annotated_rlhf = annotator_pool.annotate_head2head(outputs_1=outputs_baseline, outputs_2=outputs_rlhf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0bef5b4-fe18-46d8-a24e-94aae51785f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'win_rate': 0.4503968253968254,\n",
       " 'standard_error': 0.031341040236349975,\n",
       " 'n_wins': 113,\n",
       " 'n_wins_base': 138,\n",
       " 'n_draws': 1,\n",
       " 'n_total': 252}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head2head_to_metrics(preferences=[a[\"preference\"] for a in annotated_rlhf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebccb060-3803-4e4b-95d0-90ad5213830d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Annotating 11 examples with davinci003_4\n",
      "INFO:root:Auto annotating 11 prompts using text-davinci-003.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 200, 'temperature': 1.0}\n",
      "INFO:root:Decoding with OpenAI API model text-davinci-003 and numproc == 1.\n",
      "prompt_batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.14it/s]\n",
      "INFO:root:Annotating 19 examples with davinci003_3\n",
      "INFO:root:Auto annotating 5 prompts using text-davinci-003.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 200, 'temperature': 1.0}\n",
      "INFO:root:Decoding with OpenAI API model text-davinci-003 and numproc == 1.\n",
      "prompt_batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.95s/it]\n",
      "INFO:root:Annotating 18 examples with davinci003_2\n",
      "INFO:root:Auto annotating 18 prompts using text-davinci-003.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 200, 'temperature': 1.0}\n",
      "INFO:root:Decoding with OpenAI API model text-davinci-003 and numproc == 1.\n",
      "prompt_batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.02it/s]\n",
      "INFO:root:Annotating 16 examples with davinci003_1\n",
      "INFO:root:Auto annotating 4 prompts using text-davinci-003.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 200, 'temperature': 1.0}\n",
      "INFO:root:Decoding with OpenAI API model text-davinci-003 and numproc == 1.\n",
      "prompt_batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.91s/it]\n",
      "INFO:root:Annotating 17 examples with chatgpt_4\n",
      "INFO:root:Auto annotating 17 prompts using gpt-3.5-turbo-0301.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 20, 'temperature': 1.0, 'logit_bias': {21279: -100, 63295: -100, 4155: -100, 11995: -100, 25215: -100, 50344: -100, 59047: -100, 2196: -100, 2181: -100, 21704: -100, 19701: -100, 5207: 7, 320: 7, 64: 7, 8: 7, 65: 7}}\n",
      "INFO:root:Decoding with OpenAI API model gpt-3.5-turbo-0301 and numproc == 5.\n",
      "prompt_batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:03<00:00,  5.48it/s]\n",
      "INFO:root:Annotating 17 examples with chatgpt_3\n",
      "INFO:root:Auto annotating 17 prompts using gpt-3.5-turbo-0301.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 20, 'temperature': 1.0, 'logit_bias': {21279: -100, 63295: -100, 4155: -100, 11995: -100, 25215: -100, 50344: -100, 59047: -100, 2196: -100, 2181: -100, 21704: -100, 19701: -100, 5207: 7, 320: 7, 64: 7, 8: 7, 65: 7}}\n",
      "INFO:root:Decoding with OpenAI API model gpt-3.5-turbo-0301 and numproc == 5.\n",
      "prompt_batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:03<00:00,  5.58it/s]\n",
      "INFO:root:Annotating 29 examples with chatgpt_2\n",
      "INFO:root:Auto annotating 29 prompts using gpt-3.5-turbo-0301.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 150, 'temperature': 1.0, 'logit_bias': {21279: -100, 63295: -100, 4155: -100, 11995: -100, 25215: -100, 50344: -100, 59047: -100, 2196: -100, 2181: -100, 21704: -100, 19701: -100}}\n",
      "INFO:root:Decoding with OpenAI API model gpt-3.5-turbo-0301 and numproc == 5.\n",
      "prompt_batches:  52%|█████████████████████████████████████████████████████████▉                                                      | 15/29 [00:16<00:17,  1.28s/it]WARNING:root:OpenAIError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID eca19b61086d01924fca8eb8ba6baeda in your message.).\n",
      "WARNING:root:Hit request rate limit; retrying...\n",
      "WARNING:root:Switching to organization: org-dPb4AamVADaroNRyV4QK3Yyt for OAI API key.\n",
      "prompt_batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:41<00:00,  1.43s/it]\n",
      "INFO:root:Annotating 19 examples with chatgpt_1\n",
      "INFO:root:Auto annotating 19 prompts using gpt-3.5-turbo-0301.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 50, 'temperature': 1.0, 'logit_bias': {21279: -100, 63295: -100, 4155: -100, 11995: -100, 25215: -100, 50344: -100, 59047: -100, 2196: -100, 2181: -100, 21704: -100, 19701: -100, 5207: 7, 320: 7, 64: 7, 8: 7, 65: 7}}\n",
      "INFO:root:Decoding with OpenAI API model gpt-3.5-turbo-0301 and numproc == 5.\n",
      "prompt_batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 19/19 [00:03<00:00,  6.15it/s]\n",
      "INFO:root:Annotating 14 examples with gpt4_5\n",
      "INFO:root:Auto annotating 4 prompts using gpt-4-0314.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 250, 'temperature': 1.0}\n",
      "INFO:root:Decoding with OpenAI API model gpt-4-0314 and numproc == 5.\n",
      "prompt_batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:20<00:00,  5.09s/it]\n",
      "INFO:root:Annotating 21 examples with gpt4_4\n",
      "INFO:root:Auto annotating 21 prompts using gpt-4-0314.\n",
      "INFO:root:Kwargs to completion: {'max_tokens': 20, 'temperature': 1.0, 'logit_bias': {21279: -100, 63295: -100, 4155: -100, 11995: -100, 25215: -100, 50344: -100, 59047: -100, 2196: -100, 2181: -100, 21704: -100, 19701: -100, 5207: 7, 320: 7, 64: 7, 8: 7, 65: 7}}\n",
      "INFO:root:Decoding with OpenAI API model gpt-4-0314 and numproc == 5.\n",
      "prompt_batches:  38%|███████████████████████████████████████████                                                                      | 8/21 [00:05<00:08,  1.58it/s]"
     ]
    }
   ],
   "source": [
    "annotated_sft = annotator_pool.annotate_head2head(outputs_1=outputs_baseline, outputs_2=outputs_sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4704aec5-3aed-4689-835f-de67ffc8e1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "head2head_to_metrics(preferences=[a[\"preference\"] for a in annotated_sft])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e703c1ea-8406-4599-8a43-d5a5de63459e",
   "metadata": {},
   "source": [
    "### Configuring annotators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4927636c-96f5-4125-a553-a5be011c2a42",
   "metadata": {},
   "source": [
    "The most important argument to `PairwiseAutoAnnotator` is `annotators_config` which defines the pool of annotators. We provide the following options out of the box:\n",
    "- `annotators_config=\"annotators/annotator_pool_v0/configs.yaml\"`: ApacaFarm's default annotator pool\n",
    "- `annotators_config=\"annotators/greedy_gpt4/configs.yaml\"`: Greedy GPT4 annotator\n",
    "- `annotators_config=\"annotators/test/configs.yaml\"`: a faster text-davinci-003 annotator useful for testing\n",
    "\n",
    "Here's the desciption of `annotators_config` from the docstring:\n",
    "```\n",
    "annotators_config : Path or list of dict\n",
    "    A dictionary or path to a yaml file containing the configuration for the pool of annotators. The keys in the\n",
    "        fist dictionary should be the annotator's name, and the value should be a dictionary of the annotator's\n",
    "        configuration which should have the following keys:\n",
    "        - prompt_templates (dict): a dictionary of prompts or path to the prompts.\n",
    "        - fn_decoder (str): function in `alpaca_farm.auto_annotations.pairwise_annotators.decoders.py` for completions.\n",
    "        - decoder_kwargs (dict): kwargs for fn_decode. E.g. model_name, max_completions_tokens\n",
    "        - other kwargs to `SinglePairwiseAutoAnnotator`\n",
    "```\n",
    "\n",
    "And here is config `\"annotators/test/configs.yaml\"` of the annotator we used above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "945ba06f-cc13-436f-83f0-f074f37ea2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davinci003_3 : # text-davinci-003_v1_b5-pairwise_temp=1.0\n",
      "  prompt_templates:\n",
      "    with_inputs: \"annotators/annotator_pool_v0/text_b5_with_inputs.txt\"\n",
      "    without_inputs: \"annotators/annotator_pool_v0/text_b5_without_inputs.txt\"\n",
      "  fn_decoder: \"openai_completions\"\n",
      "  decoder_kwargs:\n",
      "    model_name: \"text-davinci-003\"\n",
      "    max_tokens: 200\n",
      "    temperature: 0.0\n",
      "  outputs_to_match:\n",
      "    1: '\\n\\(a\\)'\n",
      "    2: '\\n\\(b\\)'\n",
      "  batch_size: 5"
     ]
    }
   ],
   "source": [
    "!cat src/alpaca_farm/auto_annotations/annotators/test/configs.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0233e875-ae40-4b53-bc6b-05cf0201bbf0",
   "metadata": {},
   "source": [
    "For more information see the docstrings of the following classes (eg uncomment and run the following)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "459aa856-241b-451b-8917-da24b6f85052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from alpaca_farm.auto_annotations.pairwise_annotators import SinglePairwiseAutoAnnotator\n",
    "# PairwiseAutoAnnotator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "730ed569-d910-434c-a5d9-6600cab17701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SinglePairwiseAutoAnnotator?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d886bf-3002-4939-8751-332cf4ef0e35",
   "metadata": {},
   "source": [
    "If you want to make a new annotator, change the prompt and or the configs above. See `annotators/annotator_pool_v0/...txt` for the actual prompts we used. To see the prompt used above (which is part of our pool of prompts) uncomment and run the following line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bb96d79-e4e6-407c-b7e0-758ec75bc4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat src/alpaca_farm/auto_annotations/annotators/annotator_pool_v0/text_b5_without_inputs.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
